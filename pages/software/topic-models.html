<!doctype html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>  Software / Topic Models | akuz.me/nko
</title>
  <link rel="canonical" href="http://akuz.me/pages/software/topic-models.html">


  <link rel="stylesheet" href="http://akuz.me/theme/css/bootstrap.min.css">
  <link rel="stylesheet" href="http://akuz.me/theme/css/font-awesome.min.css">
  <link rel="stylesheet" href="http://akuz.me/theme/css/pygments/default.min.css">
  <link rel="stylesheet" href="http://akuz.me/theme/css/theme.css">

  <link rel="alternate" type="application/atom+xml" title="Full Atom Feed"
        href="http://akuz.me/feeds/all.atom.xml">
  
  <meta name="description" content="I've been actively researching Topic Models (part of Natural Language Processing, NLP) during 2011-2014. I've implemented a few enhancements to the Latent Dirichlet Allocation model: Simulated Annealing (for faster Gibbs sampling convergence) Topic Keywords (specify high probability words for specific topics) Multiprocessor Parallelisation (you can specify thread count) The first …">
  <script>
    (function(i, s, o, g, r, a, m) {
      i['GoogleAnalyticsObject'] = r;
      i[r] = i[r] || function() {
        (i[r].q = i[r].q || []).push(arguments)
      }, i[r].l = 1 * new Date();
      a = s.createElement(o);
      a.async = 1;
      a.src = g;
      m = s.getElementsByTagName(o)[0];
      m.parentNode.insertBefore(a, m)
    })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');
    ga('create', 'UA-47495265-1', 'auto');
    ga('send', 'pageview');
  </script>


</head>

<body>
  <header class="header">
    <div class="container">
<div class="row">
  <div class="col-sm-12">
    <h1 class="title"><a href="http://akuz.me/">akuz.me/nko</a></h1>
      <ul class="list-inline">
          <li class="list-inline-item"><a href="/">Home</a></li>
              <li class="list-inline-item text-muted">|</li>
            <li class="list-inline-item"><a href="http://akuz.me/pages/about.html">About</a></li>
            <li class="list-inline-item"><a href="http://akuz.me/pages/papers.html">Papers</a></li>
            <li class="list-inline-item"><a href="http://akuz.me/pages/software.html">Software</a></li>
      </ul>
  </div>
</div>    </div>
  </header>

  <div class="main">
    <div class="container">
      <h1>  Software / Topic Models
</h1>
      <hr>
  <article class="article">
    <div class="content">
      <p>I've been actively researching Topic Models (part of Natural Language Processing, NLP) during 2011-2014.</p>
<p>I've implemented a few enhancements to the  <a href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation">Latent Dirichlet Allocation</a> model:</p>
<ul>
<li>Simulated Annealing (for faster Gibbs sampling convergence)</li>
<li>Topic Keywords (specify high probability words for specific topics)</li>
<li>Multiprocessor Parallelisation (you can specify thread count)</li>
</ul>
<p>The first two are described in research notes which you can find <a href="http://akuz.me/pages/papers.html">here</a>.</p>
<p>The code itself now could probably be only useful as a historical reference...</p>
<h3>Download Source Code</h3>
<ul>
<li><a href="https://github.com/akuz/akuz-java"><i class="fa fa-github"></i>&nbsp;akuz-java</a> - various Java libraries, including:</li>
<li><code>akuz-nlp</code> - Natural Language Processing (NLP) library</li>
<li><code>akuz-nlp-run-lda</code> - How to run LDA Gibbs sampling</li>
</ul>
<h3>Download Test Data</h3>
<p>The below zip files contain abstracts (or full texts, depending on the source) of news articles. Close duplicates from the same source have been removed. The data does not have source names or timestamps. First line in each file is a title.</p>
<ul>
<li><a href="http://akuz.me/data/news_1k.zip"><i class="fa fa-file-zip-o"></i>&nbsp;news_1k.zip</a> (416 Kb) — first 1,000 news after 1 Jan 2013, 00:00:00</li>
<li><a href="http://akuz.me/data/news_10k.zip"><i class="fa fa-file-zip-o"></i>&nbsp;news_10k.zip</a> (4.3 Mb) — first 10,000 news after 1 Jan 2013, 00:00:00</li>
</ul>
<p>To use this data with algorithms from the NLP library, unpack the archive into a directory on your computer, and then specify that directory in the parameters to the program (see <code>akuz-nlp-run-lda</code> project for an example).</p>
    </div>
  </article>
    </div>
  </div>

  <footer class="footer">
    <div class="container">
<div class="row">
  <ul class="col-sm-6 list-inline">
      <li class="list-inline-item"><a href="http://akuz.me/authors.html">Authors</a></li>
    <li class="list-inline-item"><a href="http://akuz.me/archives.html">Archives</a></li>
    <li class="list-inline-item"><a href="http://akuz.me/categories.html">Categories</a></li>
  </ul>
  <p class="col-sm-6 text-sm-right text-muted">
    Generated by <a href="https://github.com/getpelican/pelican" target="_blank">Pelican</a>
    / <a href="https://github.com/nairobilug/pelican-alchemy" target="_blank">&#x2728;</a>
  </p>
</div>    </div>
  </footer>
</body>

</html>